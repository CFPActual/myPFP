{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### My assumption is there are (5) 1-year long campaigns from May 2008 to June 2013 represented in this data."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:05.235673Z",
     "start_time": "2025-11-06T04:19:02.863953Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:05.352107Z",
     "start_time": "2025-11-06T04:19:05.272818Z"
    }
   },
   "source": "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:05.390194Z",
     "start_time": "2025-11-06T04:19:05.358231Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CHECKING DATA HEALTH"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:05.425540Z",
     "start_time": "2025-11-06T04:19:05.394025Z"
    }
   },
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.038690Z",
     "start_time": "2025-11-06T04:19:06.017286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Since we might be checking for missing data repeatedly\n",
    "def summarize_missing_values(dframe):\n",
    "    counts_of_missing_per_feature = dframe.isnull().sum()\n",
    "    percentages_missing_per_feature = (counts_of_missing_per_feature / len(dframe)) * 100\n",
    "\n",
    "    missing_summary = pd.DataFrame({\n",
    "                                    'missing_count': counts_of_missing_per_feature ,\n",
    "                                    'missing_percent': percentages_missing_per_feature.round(2)\n",
    "                                })\n",
    "\n",
    "    missing_summary.sort_values(by='missing_percent', ascending=False, inplace=True)\n",
    "    print(missing_summary)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.214298Z",
     "start_time": "2025-11-06T04:19:06.183146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Is the raw data like swiss cheese\n",
    "summarize_missing_values(df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                missing_count  missing_percent\n",
      "age                         0              0.0\n",
      "campaign                    0              0.0\n",
      "nr.employed                 0              0.0\n",
      "euribor3m                   0              0.0\n",
      "cons.conf.idx               0              0.0\n",
      "cons.price.idx              0              0.0\n",
      "emp.var.rate                0              0.0\n",
      "poutcome                    0              0.0\n",
      "previous                    0              0.0\n",
      "pdays                       0              0.0\n",
      "duration                    0              0.0\n",
      "job                         0              0.0\n",
      "day_of_week                 0              0.0\n",
      "month                       0              0.0\n",
      "contact                     0              0.0\n",
      "loan                        0              0.0\n",
      "housing                     0              0.0\n",
      "default                     0              0.0\n",
      "education                   0              0.0\n",
      "marital                     0              0.0\n",
      "y                           0              0.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The local task is to predict whether or not a customer will purchase a certificate of deposit of any term length.  The global business objective is to increase the effectiveness of those telemarketing campaigns targeting term purchases."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "DROP \"duration\" AND OTHER NON-BANKING RELATED FEATURES"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.472019Z",
     "start_time": "2025-11-06T04:19:06.459073Z"
    }
   },
   "cell_type": "code",
   "source": "df_lite = df.drop(columns=[\"age\", \"job\", \"marital\", \"education\", \"month\", \"day_of_week\", \"duration\"])\n",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.562775Z",
     "start_time": "2025-11-06T04:19:06.541656Z"
    }
   },
   "cell_type": "code",
   "source": "df_lite.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   default         41188 non-null  object \n",
      " 1   housing         41188 non-null  object \n",
      " 2   loan            41188 non-null  object \n",
      " 3   contact         41188 non-null  object \n",
      " 4   campaign        41188 non-null  int64  \n",
      " 5   pdays           41188 non-null  int64  \n",
      " 6   previous        41188 non-null  int64  \n",
      " 7   poutcome        41188 non-null  object \n",
      " 8   emp.var.rate    41188 non-null  float64\n",
      " 9   cons.price.idx  41188 non-null  float64\n",
      " 10  cons.conf.idx   41188 non-null  float64\n",
      " 11  euribor3m       41188 non-null  float64\n",
      " 12  nr.employed     41188 non-null  float64\n",
      " 13  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(3), object(6)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CONVERT THE TARGET TO NUMERIC"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.604895Z",
     "start_time": "2025-11-06T04:19:06.589856Z"
    }
   },
   "source": "df_lite[\"y\"] = df_lite[\"y\"].map({\"no\": 0, \"yes\": 1})",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PREPARING FEATURE COLUMNS"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.662895Z",
     "start_time": "2025-11-06T04:19:06.609861Z"
    }
   },
   "source": [
    "# CATEGORICAL FEATURES\n",
    "categorical_cols = [\"default\", \"housing\", \"loan\", \"contact\", \"poutcome\"]\n",
    "\n",
    "# NUMERIC FEATURES\n",
    "numeric_cols = [\"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"]\n",
    "\n",
    "# ISOLATE TARGET\n",
    "X_lite = df_lite.drop(columns=[\"y\"])\n",
    "y = df_lite[\"y\"]\n",
    "\n",
    "# ENCODING CATEGORICAL VARIABLES\n",
    "nominal_enc = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "preprocessor = ColumnTransformer(transformers=[(\"nominal\", nominal_enc, categorical_cols), (\"numeric\", \"passthrough\", numeric_cols)])\n",
    "\n",
    "# CREAT/APPLY THE FE PIPELINE\n",
    "full_pipeline = Pipeline([ (\"encode\", preprocessor)])\n",
    "X_transformed = full_pipeline.fit_transform(X_lite)\n",
    "\n",
    "# WRANGLING FEATURE NAMES\n",
    "nominal_feature_names = full_pipeline.named_steps[\"encode\"].transformers_[0][1].get_feature_names_out(categorical_cols)\n",
    "final_columns = list(nominal_feature_names) + numeric_cols\n",
    "\n",
    "X = pd.DataFrame(X_transformed, columns=final_columns)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.679025Z",
     "start_time": "2025-11-06T04:19:06.669022Z"
    }
   },
   "source": "X.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.742510Z",
     "start_time": "2025-11-06T04:19:06.724510Z"
    }
   },
   "cell_type": "code",
   "source": "X.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   default_no            41188 non-null  float64\n",
      " 1   default_unknown       41188 non-null  float64\n",
      " 2   default_yes           41188 non-null  float64\n",
      " 3   housing_no            41188 non-null  float64\n",
      " 4   housing_unknown       41188 non-null  float64\n",
      " 5   housing_yes           41188 non-null  float64\n",
      " 6   loan_no               41188 non-null  float64\n",
      " 7   loan_unknown          41188 non-null  float64\n",
      " 8   loan_yes              41188 non-null  float64\n",
      " 9   contact_cellular      41188 non-null  float64\n",
      " 10  contact_telephone     41188 non-null  float64\n",
      " 11  poutcome_failure      41188 non-null  float64\n",
      " 12  poutcome_nonexistent  41188 non-null  float64\n",
      " 13  poutcome_success      41188 non-null  float64\n",
      " 14  campaign              41188 non-null  float64\n",
      " 15  pdays                 41188 non-null  float64\n",
      " 16  previous              41188 non-null  float64\n",
      " 17  emp.var.rate          41188 non-null  float64\n",
      " 18  cons.price.idx        41188 non-null  float64\n",
      " 19  cons.conf.idx         41188 non-null  float64\n",
      " 20  euribor3m             41188 non-null  float64\n",
      " 21  nr.employed           41188 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SCALING FOR KNN, LOGISTIC REGRESSION AND SUPPORT VECTOR MACHINE, DECISION TREE WILL JUST HAVE TO COME ALONG FOR THE RIDE."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.807905Z",
     "start_time": "2025-11-06T04:19:06.763080Z"
    }
   },
   "source": [
    "# Split data into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y )\n",
    "\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data ONLY\n",
    "scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "# Transform all sets\n",
    "X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.833142Z",
     "start_time": "2025-11-06T04:19:06.815129Z"
    }
   },
   "source": [
    "print(f\"X_train.shape--> {X_train.shape}, X_test.shape--> {X_test.shape}\" )\n",
    "print(f\"y_train.shape--> {y_train.shape}, y_test.shape--> {y_test.shape}\" )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape--> (32950, 22), X_test.shape--> (8238, 22)\n",
      "y_train.shape--> (32950,), y_test.shape--> (8238,)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.864264Z",
     "start_time": "2025-11-06T04:19:06.852196Z"
    }
   },
   "source": [
    "baseline_model = DummyClassifier(strategy='most_frequent', random_state=42).fit(X_train, y_train)\n",
    "baseline_performance = baseline_model.score(X_test, y_test)\n",
    "print(f\"The scores to beat = baseline performance = {baseline_performance}; no is the common response\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores to beat = baseline performance = 0.8873512988589464; no is the common response\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.957828Z",
     "start_time": "2025-11-06T04:19:06.887095Z"
    }
   },
   "source": "basic_model_lgr = LogisticRegression().fit(X_train, y_train)",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:06.973127Z",
     "start_time": "2025-11-06T04:19:06.965124Z"
    }
   },
   "source": "print(basic_model_lgr.score(X_test, y_test))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9009468317552805\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:19:07.024360Z",
     "start_time": "2025-11-06T04:19:07.001810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_models(model_set, return_best=0):\n",
    "    best_models = {}\n",
    "    results = []\n",
    "\n",
    "    for name, (model, params) in model_set.items():\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline([(name, model)])\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=params, cv=5, n_jobs=-1)\n",
    "\n",
    "        # Fit the model and time it\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "\n",
    "        # Get the best estimator\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_models[name] = best_model              # <── store it\n",
    "\n",
    "        # Evaluate on training and test sets\n",
    "        train_score = best_model.score(X_train, y_train)\n",
    "        test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "           # Append the results\n",
    "        results.append([name, fit_time, train_score, test_score])\n",
    "\n",
    "    # Create the results DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['model', 'train time', 'train accuracy', 'test accuracy'])\n",
    "    results_df.set_index('model', inplace=True)\n",
    "\n",
    "    # Save to JSON (for submission if needed)\n",
    "    results_df.to_json('data/model_results.json')\n",
    "    df = pd.read_json(r'data/model_results.json')\n",
    "    print(df)\n",
    "    return best_models if return_best else None\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:22:47.125419Z",
     "start_time": "2025-11-06T04:19:07.026132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# basic models with default hyperparameters\n",
    "default_models = {\n",
    "    'logisticregression': (LogisticRegression(), {'logisticregression__C': [1.0]}),\n",
    "    'knn': (KNeighborsClassifier(), {'knn__n_neighbors': [5]}),\n",
    "    'decisiontree': (DecisionTreeClassifier(), {'decisiontree__max_depth': [None]}),\n",
    "    'svc': (SVC(), {'svc__C': [1.0], 'svc__kernel': ['linear']})\n",
    "}\n",
    "compare_models(default_models)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    train time  train accuracy  test accuracy\n",
      "logisticregression    2.975433        0.900061       0.900947\n",
      "knn                   2.837421        0.909712       0.896334\n",
      "decisiontree          1.807778        0.938816       0.889051\n",
      "svc                 200.156393        0.897481       0.897669\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:24:48.795492Z",
     "start_time": "2025-11-06T04:23:05.698216Z"
    }
   },
   "source": [
    "# Pimproved models with some new choices for hyperparameters\n",
    "improved_models = {\n",
    "    'logisticregression': (LogisticRegression(max_iter=2000), {'logisticregression__C': [0.1, 0.5, 1.0]}),\n",
    "    'knn': (KNeighborsClassifier(), {'knn__n_neighbors': [2, 4, 6, int(np.sqrt(len(X_train))/2)]}),\n",
    "    'decisiontree': (DecisionTreeClassifier(), {'decisiontree__max_depth': [5, 7, 20]}),\n",
    "    'svc': (SVC(), {'svc__C': [0.1, 0.5, 1.0], 'svc__kernel': ['rbf']})\n",
    "}\n",
    "best_improved_models = compare_models(improved_models, return_best=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    train time  train accuracy  test accuracy\n",
      "logisticregression    0.192110        0.899939       0.900825\n",
      "knn                   1.097926        0.900364       0.901797\n",
      "decisiontree          0.130260        0.902276       0.903253\n",
      "svc                  22.450516        0.901517       0.902403\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "REVIEWING OTHER PERFORMANCE METRICS FOR THE IMPROVED MODEL SET"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:24:48.858405Z",
     "start_time": "2025-11-06T04:24:48.842623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_model_metric_stack(model_set):\n",
    "    eval_rows = []\n",
    "\n",
    "    for name, model in fitted_models.items():\n",
    "        if model is None:\n",
    "            continue\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            y_prob = model.decision_function(X_test)\n",
    "        else:\n",
    "            y_prob = None\n",
    "\n",
    "        # Core metrics\n",
    "        acc  = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        rec  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        f1   = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "        # Ranking metrics (skip if no probabilities)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "        pr_auc  = average_precision_score(y_test, y_prob) if y_prob is not None else None\n",
    "\n",
    "        eval_rows.append([name, acc, prec, rec, f1, roc_auc, pr_auc])\n",
    "\n",
    "    # results to DataFrame\n",
    "    eval_df = pd.DataFrame(\n",
    "        eval_rows,\n",
    "        columns=[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\", \"pr_auc\"]\n",
    "    ).set_index(\"model\")\n",
    "\n",
    "    print(eval_df.round(3))"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:25:00.800595Z",
     "start_time": "2025-11-06T04:24:48.899850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fitted_models = {\n",
    "    'baseline': baseline_model,\n",
    "    **best_improved_models\n",
    "}\n",
    "create_model_metric_stack(fitted_models)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    accuracy  precision  recall     f1  roc_auc  pr_auc\n",
      "model                                                                  \n",
      "baseline               0.887      0.000   0.000  0.000    0.500   0.113\n",
      "logisticregression     0.901      0.725   0.193  0.305    0.791   0.455\n",
      "knn                    0.902      0.688   0.235  0.350    0.795   0.454\n",
      "decisiontree           0.903      0.669   0.279  0.394    0.798   0.444\n",
      "svc                    0.902      0.685   0.248  0.364    0.684   0.381\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CLOSING COMMENTS"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using the CRISP-DM framework, I predicted client term-deposit subscriptions from clean, but imbalanced bank-marketing data.\n",
    "Four tuned classifiers—Logistic Regression, KNN, Decision Tree, and SVC—all exceeded the 0.887 baseline, achieving ~0.90 accuracy.\n",
    "The Decision Tree performed best overall (test = 0.903, F1 = 0.394, ROC-AUC = 0.798), offering strong interpretability and balanced precision-recall.\n",
    "Logistic Regression remained the most efficient (train < 0.2 s) and produced competitive precision (0.73) with solid ranking ability (ROC-AUC = 0.791).\n",
    "Economic and campaign variables drove prediction power far more than demographics.\n",
    "Next steps could include selecting a final model, refining hyperparameters, and exploring threshold adjustments or class-weighted, cost-sensitive objectives to improve recall while maintaining business value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
